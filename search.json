[
  {
    "objectID": "README.html",
    "href": "README.html",
    "title": "simon_et_al",
    "section": "",
    "text": "FGF treated and MEK inhibited mouse and human blastocysts"
  },
  {
    "objectID": "README.html#checklist-before-submitting",
    "href": "README.html#checklist-before-submitting",
    "title": "simon_et_al",
    "section": "1 Checklist before submitting",
    "text": "1 Checklist before submitting\n\nWere the processed data uploaded to Zenodo? Paste DOI here\nDid you create gh-pages for deployment?\nPush the code and run quarto publish gh-pages"
  },
  {
    "objectID": "notebooks/01_human_loadAndIntegrate.html",
    "href": "notebooks/01_human_loadAndIntegrate.html",
    "title": "08 - Niakan human",
    "section": "",
    "text": "%matplotlib inline\n%load_ext autoreload\n%autoreload 2\n\nimport scvi\nimport scanpy as sc\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport anndata as ad\n\n\nimport sys; sys.path.append(\"../scripts/\")\nfrom helpers import normalize_smartseq\nGENE_LEN = '/home/gkb340/Brickman/shared/references/homo_sapiens/ensembl/GRCh38_110/Homo_sapiens.GRCh38.110.gene_length.tsv'\nREMAKE_FIGURES = False"
  },
  {
    "objectID": "notebooks/01_human_loadAndIntegrate.html#load-in-libraries",
    "href": "notebooks/01_human_loadAndIntegrate.html#load-in-libraries",
    "title": "08 - Niakan human",
    "section": "",
    "text": "%matplotlib inline\n%load_ext autoreload\n%autoreload 2\n\nimport scvi\nimport scanpy as sc\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport anndata as ad\n\n\nimport sys; sys.path.append(\"../scripts/\")\nfrom helpers import normalize_smartseq\nGENE_LEN = '/home/gkb340/Brickman/shared/references/homo_sapiens/ensembl/GRCh38_110/Homo_sapiens.GRCh38.110.gene_length.tsv'\nREMAKE_FIGURES = False"
  },
  {
    "objectID": "notebooks/01_human_loadAndIntegrate.html#load-in-data",
    "href": "notebooks/01_human_loadAndIntegrate.html#load-in-data",
    "title": "08 - Niakan human",
    "section": "2 Load in data",
    "text": "2 Load in data\n\n2.1 Initial sequencing from the Crick\n\ncrick_adata = sc.read_h5ad(\"../data/external/niakan_et_al/niakan_combined_matrix.h5ad\")\n\nNameError: name 'sc' is not defined\n\n\n\ncrick_adata.obs['sample_fine'] = crick_adata.obs['sample'].str.split('_', expand=True)[0].to_list()\nSimon_metadata = pd.read_table(\"../data/processed/Samples_LIMSID.csv\" ,sep = ',')\ncrick_adata.obs = crick_adata.obs.join(Simon_metadata[['LIMS.ID','Embryo']].set_index('LIMS.ID'), on='sample_fine')\n\n\ncrick_adata.obs_names = crick_adata.obs['Embryo'] + '_' + crick_adata.obs['sample']\n\ncrick_adata.obs['treatment'] = 'DMSO'\ncrick_adata.obs.loc[crick_adata.obs_names.str.contains('Ulix'), 'treatment'] = 'Ulix'\n\ncrick_adata.obs['batch'] = \"NIAKAN_1\"\ncrick_adata.obs['experiment'] = \"Simon et al, 2024\"\ncrick_adata.obs['technology'] = \"SMART-seq2\"\ncrick_adata\n\nAnnData object with n_obs × n_vars = 132 × 62754\n    obs: 'sample', 'fastq_1', 'fastq_2', 'sample_fine', 'Embryo', 'treatment', 'batch', 'experiment', 'technology'\n    var: 'gene_symbol'\n\n\n\ncrick_adata.var[\"mt\"] = crick_adata.var.gene_symbol.str.startswith(\"MT-\")\nsc.pp.calculate_qc_metrics(crick_adata, qc_vars=[\"mt\"], inplace=True, log1p=True)\nsc.pl.violin(crick_adata, [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\"], jitter=0.4, multi_panel=True)\nsc.pl.scatter(crick_adata, \"total_counts\", \"n_genes_by_counts\", color=\"pct_counts_mt\")\nsns.histplot(x=crick_adata.obs['pct_counts_mt'], bins=30)\n\n\n\n\n\n\n\n&lt;Axes: xlabel='pct_counts_mt', ylabel='Count'&gt;\n\n\n\n\n\n\ncrick_adata = crick_adata[crick_adata.obs.pct_counts_mt &lt; 30].copy()\ncrick_adata = crick_adata[crick_adata.obs.n_genes_by_counts &gt; 8000].copy()\n\n\nsc.pl.violin(crick_adata, [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\"], jitter=0.4, multi_panel=True)\nsc.pl.scatter(crick_adata, \"total_counts\", \"n_genes_by_counts\", color=\"pct_counts_mt\")\nsns.histplot(x=crick_adata.obs['pct_counts_mt'], bins=30)\n\n\n\n\n\n\n\n&lt;Axes: xlabel='pct_counts_mt', ylabel='Count'&gt;\n\n\n\n\n\n\n\n2.2 Sequencing from Cambridge\n\nbabraham_adata = sc.read_h5ad(\"../data/assays/SCR_NS_20240521/processed/GRCh38_110/combined_matrix.merged.h5ad\")\n\n\nbabraham_adata.obs_names = babraham_adata.obs['sample']\n\nbabraham_adata.obs['treatment'] = 'DMSO'\nbabraham_adata.obs.loc[babraham_adata.obs_names.str.contains('Ulix'), 'treatment'] = 'Ulix'\n\nbabraham_adata.obs['batch'] = \"NIAKAN_2\"\nbabraham_adata.obs['experiment'] = \"Simon et al, 2024\"\nbabraham_adata.obs['technology'] = \"SMART-seq2\"\nbabraham_adata\n\nAnnData object with n_obs × n_vars = 100 × 62754\n    obs: 'sample', 'fastq_1', 'fastq_2', 'treatment', 'batch', 'experiment', 'technology'\n    var: 'gene_symbol'\n\n\n\nbabraham_adata.var[\"mt\"] = babraham_adata.var.gene_symbol.str.startswith(\"MT-\")\nsc.pp.calculate_qc_metrics(babraham_adata, qc_vars=[\"mt\"], inplace=True, log1p=True)\nsc.pl.violin(babraham_adata, [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\"], jitter=0.4, multi_panel=True)\nsc.pl.scatter(babraham_adata, \"total_counts\", \"n_genes_by_counts\", color=\"pct_counts_mt\")\nsns.histplot(x=babraham_adata.obs['pct_counts_mt'], bins=30)\n\n\n\n\n\n\n\n&lt;Axes: xlabel='pct_counts_mt', ylabel='Count'&gt;\n\n\n\n\n\n\nbabraham_adata = babraham_adata[babraham_adata.obs.pct_counts_mt &lt; 30].copy()\nbabraham_adata = babraham_adata[babraham_adata.obs.n_genes_by_counts &gt; 8000].copy()\n\n\nsc.pl.violin(babraham_adata, [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\"], jitter=0.4, multi_panel=True)\nsc.pl.scatter(babraham_adata, \"total_counts\", \"n_genes_by_counts\", color=\"pct_counts_mt\")\nsns.histplot(x=babraham_adata.obs['pct_counts_mt'], bins=30)\n\n\n\n\n\n\n\n&lt;Axes: xlabel='pct_counts_mt', ylabel='Count'&gt;\n\n\n\n\n\n\n\n2.3 Concatenate anndata\n\nadata = ad.concat([crick_adata, babraham_adata])\n\n\nadata.obs\n\n\n\n\n\n\n\n\nsample\nfastq_1\nfastq_2\ntreatment\nbatch\nexperiment\ntechnology\nn_genes_by_counts\nlog1p_n_genes_by_counts\ntotal_counts\nlog1p_total_counts\npct_counts_in_top_50_genes\npct_counts_in_top_100_genes\npct_counts_in_top_200_genes\npct_counts_in_top_500_genes\ntotal_counts_mt\nlog1p_total_counts_mt\npct_counts_mt\n\n\n\n\nHuman_Ulix_5_SIM5110A133\nSIM5110A133\n/scratch/Brickman/pipelines/Niakan2024_human/r...\n/scratch/Brickman/pipelines/Niakan2024_human/r...\nUlix\nNIAKAN_1\nSimon et al, 2024\nSMART-seq2\n12540\n9.436759\n16318175.0\n16.607790\n27.067255\n33.021707\n40.767923\n53.448765\n2596380.0\n14.769629\n15.910971\n\n\nHuman_Ulix_4_SIM5110A88\nSIM5110A88\n/scratch/Brickman/pipelines/Niakan2024_human/r...\n/scratch/Brickman/pipelines/Niakan2024_human/r...\nUlix\nNIAKAN_1\nSimon et al, 2024\nSMART-seq2\n13011\n9.473627\n16349510.0\n16.609709\n23.037987\n29.586251\n37.693747\n51.772891\n1259369.0\n14.046123\n7.702793\n\n\nHuman_Ulix_5_SIM5110A127\nSIM5110A127\n/scratch/Brickman/pipelines/Niakan2024_human/r...\n/scratch/Brickman/pipelines/Niakan2024_human/r...\nUlix\nNIAKAN_1\nSimon et al, 2024\nSMART-seq2\n12053\n9.397152\n6229982.0\n15.644884\n27.717287\n34.285813\n42.493606\n56.090708\n1005475.0\n13.820971\n16.139294\n\n\nHuman_Ulix_4_SIM5110A85\nSIM5110A85\n/scratch/Brickman/pipelines/Niakan2024_human/r...\n/scratch/Brickman/pipelines/Niakan2024_human/r...\nUlix\nNIAKAN_1\nSimon et al, 2024\nSMART-seq2\n14246\n9.564302\n24619864.0\n17.019064\n19.988749\n25.531935\n33.104822\n46.332910\n2569475.0\n14.759212\n10.436593\n\n\nHuman_Ulix_5_SIM5110A142\nSIM5110A142\n/scratch/Brickman/pipelines/Niakan2024_human/r...\n/scratch/Brickman/pipelines/Niakan2024_human/r...\nUlix\nNIAKAN_1\nSimon et al, 2024\nSMART-seq2\n10535\n9.262553\n13425119.0\n16.412638\n23.108585\n31.311454\n41.168916\n56.296395\n788035.0\n13.577299\n5.869855\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nHuman_Ulix_7_1\nHuman_Ulix_7_1\n/maps/projects/dan1/data/Brickman/assays/SCR_N...\n/maps/projects/dan1/data/Brickman/assays/SCR_N...\nUlix\nNIAKAN_2\nSimon et al, 2024\nSMART-seq2\n12338\n9.420520\n7991007.0\n15.893827\n20.325098\n26.809174\n35.067495\n49.236786\n538162.0\n13.195917\n6.734595\n\n\nHuman_DMSO_6_18\nHuman_DMSO_6_18\n/maps/projects/dan1/data/Brickman/assays/SCR_N...\n/maps/projects/dan1/data/Brickman/assays/SCR_N...\nDMSO\nNIAKAN_2\nSimon et al, 2024\nSMART-seq2\n9591\n9.168685\n1832853.0\n14.421385\n23.418299\n29.630854\n37.395907\n51.251028\n220061.0\n12.301664\n12.006473\n\n\nHuman_Ulix_6_6\nHuman_Ulix_6_6\n/maps/projects/dan1/data/Brickman/assays/SCR_N...\n/maps/projects/dan1/data/Brickman/assays/SCR_N...\nUlix\nNIAKAN_2\nSimon et al, 2024\nSMART-seq2\n11746\n9.371353\n12517080.0\n16.342606\n20.012575\n26.891527\n35.473273\n50.137876\n913879.0\n13.725454\n7.301055\n\n\nHuman_Ulix_6_30\nHuman_Ulix_6_30\n/maps/projects/dan1/data/Brickman/assays/SCR_N...\n/maps/projects/dan1/data/Brickman/assays/SCR_N...\nUlix\nNIAKAN_2\nSimon et al, 2024\nSMART-seq2\n13966\n9.544453\n27490648.0\n17.129356\n18.133076\n24.556694\n33.008141\n47.091940\n1456117.0\n14.191284\n5.296772\n\n\nHuman_Ulix_7_8\nHuman_Ulix_7_8\n/maps/projects/dan1/data/Brickman/assays/SCR_N...\n/maps/projects/dan1/data/Brickman/assays/SCR_N...\nUlix\nNIAKAN_2\nSimon et al, 2024\nSMART-seq2\n12450\n9.429556\n47063196.0\n17.667002\n20.350137\n27.642863\n36.563244\n51.822529\n2275928.0\n14.637898\n4.835897\n\n\n\n\n89 rows × 18 columns\n\n\n\n\nsc.pl.violin(adata, [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\"], jitter=0.4, multi_panel=True)\nsc.pl.scatter(adata, \"total_counts\", \"n_genes_by_counts\", color=\"pct_counts_mt\")\nsns.histplot(x=adata.obs['pct_counts_mt'], bins=30)\n\n\n\n\n\n\n\n&lt;Axes: xlabel='pct_counts_mt', ylabel='Count'&gt;\n\n\n\n\n\n\nadata = normalize_smartseq(adata, GENE_LEN)\nadata.layers[\"counts\"] = adata.X.copy()\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nadata.raw = adata\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 62663\n\n\n\nsc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=3_000)\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:75: UserWarning: `flavor='seurat_v3'` expects raw count data, but non-integers were found.\n  warnings.warn(\n\n\n\nsc.tl.pca(adata)\n\n\nsc.pl.pca(adata, color=['treatment', 'batch'])\n\n\n\n\n\ndel adata.varm['PCs']\n\n\nadata.write(\"../results/niakan_08.adata.h5ad\")"
  },
  {
    "objectID": "notebooks/01_human_loadAndIntegrate.html#model-predictions",
    "href": "notebooks/01_human_loadAndIntegrate.html#model-predictions",
    "title": "08 - Niakan human",
    "section": "3 Model predictions",
    "text": "3 Model predictions\n\nlvae = scvi.model.SCANVI.load('/home/gkb340/Brickman/projects/proks-salehin-et-al-v2/results/100_human_integration/scanvi_ns_15/')\nscvi.model.SCANVI.prepare_query_anndata(adata, lvae)\nlvae_q = scvi.model.SCANVI.load_query_data(adata, lvae)\n\nINFO     File                                                                                                      \n         /home/gkb340/Brickman/projects/proks-salehin-et-al-v2/results/100_human_integration/scanvi_ns_15/model.pt \n         already downloaded                                                                                        \nINFO     Found 100.0% reference vars in query data.                                                                \n\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scvi/model/base/_utils.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(model_path, map_location=map_location)\n/projects/dan1/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scvi/data/_manager.py:215: UserWarning: Missing labels key ct. Filling in with unlabeled category Unknown.\n  field_registry[_constants._STATE_REGISTRY_KEY] = field.transfer_field(\n\n\n\nlvae_q.train(max_epochs=20, plan_kwargs=dict(weight_decay=0.0), check_val_every_n_epoch=10, early_stopping=True)\n\nINFO     Training for 20 epochs.                                                                                   \nEpoch 20/20: 100%|██████████| 20/20 [00:01&lt;00:00, 11.64it/s, v_num=1, train_loss_step=5.64e+3, train_loss_epoch=5.64e+3]Epoch 20/20: 100%|██████████| 20/20 [00:01&lt;00:00, 13.04it/s, v_num=1, train_loss_step=5.64e+3, train_loss_epoch=5.64e+3]\n\n\nGPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nSLURM auto-requeueing enabled. Setting signal handlers.\n/projects/dan1/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/projects/dan1/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n/projects/dan1/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n`Trainer.fit` stopped: `max_epochs=20` reached.\n\n\n\nadata.obsm[\"X_scANVI\"] = lvae_q.get_latent_representation()\nadata.obs['prediction'] = lvae_q.predict()\nadata.obs['entropy'] = 1 - lvae_q.predict(soft=True).max(axis=1)\n\n\nsc.pp.neighbors(adata)\nsc.tl.umap(adata)\n\n2024-10-21 11:49:29.974023: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\n\nsc.pl.umap(adata, color=['prediction', 'treatment','batch'], size = 20)\n\n\n\n\n\nsc.metrics.confusion_matrix('treatment', 'prediction', normalize=False, data=adata.obs)\n\n\n\n\n\n\n\nprediction\nEpiblast_6.0\nEpiblast_7.0\nInner Cell Mass\nLate epiblast\nPrimitive Endoderm\nTrophectoderm_6.0\nTrophectoderm_7.0\nTrophectoderm_8.0\nTrophectoderm_9.0\n\n\ntreatment\n\n\n\n\n\n\n\n\n\n\n\n\n\nDMSO\n1\n3\n1\n1\n7\n3\n9\n1\n10\n\n\nUlix\n7\n9\n1\n0\n4\n5\n19\n1\n7\n\n\n\n\n\n\n\n\nsc.metrics.confusion_matrix('batch', 'prediction', normalize=False, data=adata.obs)\n\n\n\n\n\n\n\nprediction\nEpiblast_6.0\nEpiblast_7.0\nInner Cell Mass\nLate epiblast\nPrimitive Endoderm\nTrophectoderm_6.0\nTrophectoderm_7.0\nTrophectoderm_8.0\nTrophectoderm_9.0\n\n\nbatch\n\n\n\n\n\n\n\n\n\n\n\n\n\nNIAKAN_1\n2\n3\n0\n0\n0\n3\n9\n0\n8\n\n\nNIAKAN_2\n6\n9\n2\n1\n11\n5\n19\n2\n9\n\n\n\n\n\n\n\n\nadata.obs['treatment'].value_counts()\n\nUlix    53\nDMSO    36\nName: treatment, dtype: int64\n\n\n\nadata.write(\"../results/niakan_08.withPredictions.adata.h5ad\")"
  },
  {
    "objectID": "notebooks/01_mouse_loadAndIntegrate.html",
    "href": "notebooks/01_mouse_loadAndIntegrate.html",
    "title": "Niakan mouse treatment (follow-up on 06 analysis)",
    "section": "",
    "text": "!which pip\n\n~/projects/data/Brickman/conda/envs/scvi-1.1.5/bin/pip\n%matplotlib inline\n%load_ext autoreload\n%autoreload 2\n\nimport scvi\nimport scanpy as sc\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport jax\njax.devices()\n\n[CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3)]\nimport sys; sys.path.append(\"../scripts/\")\nfrom helpers import normalize_smartseq\nGENE_LEN = '~/Brickman/shared/references/mus_musculus/ensembl/GRCm38_102/Mus_musculus_GRCm38_102_gene_length.txt'\nimport urllib.request, json\n\ncc_url = \"https://github.com/brickmanlab/project-template/raw/master/%7B%7B%20cookiecutter.project_name%20%7D%7D/data/external/mouse_cell_cycle_genes.json\"\nwith urllib.request.urlopen(cc_url) as url:\n    cc_dict = json.load(url)\n    CC = sum(list(cc_dict.values()), [])"
  },
  {
    "objectID": "notebooks/01_mouse_loadAndIntegrate.html#analysis",
    "href": "notebooks/01_mouse_loadAndIntegrate.html#analysis",
    "title": "Niakan mouse treatment (follow-up on 06 analysis)",
    "section": "1 1. Analysis",
    "text": "1 1. Analysis\n\nadata = sc.read_h5ad(\"../data/external/niakan_et_al/mouse/mtx_conversions/combined_matrix.h5ad\")\nadata.obs['LIMS.ID'] = adata.obs['sample'].str.split('_', expand=True).iloc[:, 0]\nadata.obs = adata.obs.merge(pd.read_csv(\"../data/processed/Samples_LIMSID.csv\"), \n                            left_on='LIMS.ID', right_on='LIMS.ID', how='left').set_index(adata.obs_names)\nadata.obs['batch'] = \"NIAKAN_1\"\nadata.obs['experiment'] = \"Simon et al, 2024\"\nadata.obs['technology'] = \"SMART-seq2\"\n\nadata\n\nAnnData object with n_obs × n_vars = 288 × 55487\n    obs: 'sample', 'fastq_1', 'fastq_2', 'LIMS.ID', 'Sample.name', 'Vol.ul', 'Conc.pg/ul', 'Mass.ng', 'QC', 'Plate.no', 'Species', 'Sample.collection.date', 'Embryo', 'Treatment', 'Stage', 'cDNA.prep.date', 'Lot.no.cDNA.kit', 'ASF.submission.date', 'batch', 'experiment', 'technology'\n    var: 'gene_symbol'\n\n\n\nadata = adata[adata.obs.QC == \"Pass\"].copy()\nadata = adata[~adata.obs.Treatment.isna()].copy()\n\n\nadata.var['mt'] = adata.var.gene_symbol.str.startswith('mt-')\nsc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n\n\nfig, ax = plt.subplots(1, 3, figsize=[10, 3])\nsns.violinplot(y=adata.obs['pct_counts_mt'], orient='v', cut=0, ax=ax[0])\nsns.violinplot(y=adata.obs['total_counts'], orient='v', cut=0, ax=ax[1])\nsns.violinplot(y=adata.obs['n_genes_by_counts'], orient='v', cut=0, ax=ax[2])\nfig.tight_layout()\n\n\n\n\n\nsc.pl.scatter(adata, \"total_counts\", \"n_genes_by_counts\", color=\"pct_counts_mt\")\n\n\n\n\n\nadata = adata[adata.obs.pct_counts_mt &lt; 15].copy()\n\n\nsc.pl.scatter(adata, \"total_counts\", \"n_genes_by_counts\", color=\"pct_counts_mt\")\n\n\n\n\n\n# sc.pp.filter_cells(adata, min_counts=2.5e5)\n# sc.pp.filter_cells(adata, max_counts=1e7)\n# sc.pp.filter_cells(adata, min_genes=2_000)"
  },
  {
    "objectID": "notebooks/01_mouse_loadAndIntegrate.html#prep-for-model",
    "href": "notebooks/01_mouse_loadAndIntegrate.html#prep-for-model",
    "title": "Niakan mouse treatment (follow-up on 06 analysis)",
    "section": "2 2. Prep for model",
    "text": "2 2. Prep for model\n\nadata = normalize_smartseq(adata, GENE_LEN)\n\nSMART-SEQ: Normalization\nSMART-SEQ: Common genes 55364\n\n\n\nadata.var['gene_id'] = adata.var_names\nadata.var_names = adata.var.gene_symbol.str.lower().values\nadata.var_names_make_unique()\n\n\nadata.layers[\"counts\"] = adata.X.copy()\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nadata.raw = adata\n\n\nsc.pp.highly_variable_genes(adata, flavor=\"cell_ranger\", n_top_genes=3_000, batch_key=\"batch\")\n\n\nsc.tl.pca(adata)\n\n\nsc.pl.pca(adata, color='Treatment')\n\n\n\n\n\nsc.pl.pca(adata, color = [\n    'pou5f1', 'sox2', 'nanog',\n    'gata6', 'gata4', 'pdgfra',\n    'cdx2', 'hand1', 'krt7'\n], ncols=3)"
  },
  {
    "objectID": "notebooks/01_mouse_loadAndIntegrate.html#load-and-retrain-model",
    "href": "notebooks/01_mouse_loadAndIntegrate.html#load-and-retrain-model",
    "title": "Niakan mouse treatment (follow-up on 06 analysis)",
    "section": "3 3. Load and retrain model",
    "text": "3 3. Load and retrain model\n\n3.1 3.0. Training\n\nvae = scvi.model.SCVI.load('/home/fdb589/Brickman/projects/proks-salehin-et-al-v2/results/100_mouse_integration/scvi')\nvae\n\n\nvae.adata.obs['ct_custom'] = vae.adata.obs.ct.replace('E3.75-ICM', 'Unknown')\n\n\nlvae = scvi.model.SCANVI.from_scvi_model(vae, labels_key=\"ct_custom\", unlabeled_category=\"Unknown\")\nlvae.train(max_epochs=20, n_samples_per_label=15)\n\n\nlvae.save(\"../results/07_mouse_scanvi_ns_15\", overwrite=True, save_anndata=True)\n\n\nlvae.adata.obs['predictions'] = lvae.predict()\n\n\norder = lvae.adata.obs.ct_custom.cat.categories.drop('Unknown')\nsns.heatmap(sc.metrics.confusion_matrix(\"ct\", \"predictions\", lvae.adata.obs).loc[order, order], linewidth=.5, vmin=0, vmax=1)\n\n\npd.crosstab(lvae.adata.obs.ct_custom, lvae.adata.obs.predictions).loc[['Unknown']]\n\n\n\n3.2 3.1. Predict\n\nlvae = scvi.model.SCANVI.load('../results/07_mouse_scanvi_ns_15/')\n\nTrainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scvi/model/base/_utils.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(model_path, map_location=map_location)\n\n\nINFO     File ../results/07_mouse_scanvi_ns_15/model.pt already downloaded                                         \n\n\n\nscvi.model.SCANVI.prepare_query_anndata(adata, lvae)\nlvae_q = scvi.model.SCANVI.load_query_data(adata, lvae)\n\nINFO     Found 100.0% reference vars in query data.                                                                \n\n\nTrainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scvi/data/_manager.py:215: UserWarning: Missing labels key ct_custom. Filling in with unlabeled category Unknown.\n  field_registry[_constants._STATE_REGISTRY_KEY] = field.transfer_field(\n\n\n\nlvae_q.train(max_epochs=100, plan_kwargs=dict(weight_decay=0.0), check_val_every_n_epoch=10, early_stopping=True)\n\nINFO     Training for 100 epochs.                                                                                  \nEpoch 75/100:  75%|███████▌  | 75/100 [00:10&lt;00:03,  7.19it/s, v_num=1, train_loss_step=4.95e+3, train_loss_epoch=4.83e+3]\nMonitored metric elbo_validation did not improve in the last 45 records. Best score: 4459.801. Signaling Trainer to stop.\n\n\nTrainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=223` in the `DataLoader` to improve performance.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=223` in the `DataLoader` to improve performance.\n\n\n\nadata.obsm[\"X_scANVI\"] = lvae_q.get_latent_representation()\nadata.obs['prediction'] = lvae_q.predict()\nadata.obs['entropy'] = 1 - lvae_q.predict(soft=True).max(axis=1)\n\nlvae_q.adata.obsm[\"X_scANVI\"] = lvae_q.get_latent_representation()\nlvae_q.adata.obs['prediction'] = lvae_q.predict()\nlvae_q.adata.obs['entropy'] = 1 - lvae_q.predict(soft=True).max(axis=1)\n\n\nsc.pl.pca(adata, color = ['prediction', 'entropy', 'Treatment'], wspace=0.2, vmax=1)\n\n\n\n\n\nfig, ax = plt.subplots(1, adata.obs.prediction.unique().size, sharex=True, figsize=[20, 3])\nfor idx, p in enumerate(adata.obs.prediction.cat.categories):\n    adata.obs.query('prediction == @p')['entropy']\\\n        .plot.hist(bins=30, ax=ax[idx], title=p, xlabel='', xlim=(-0.01,1),\n                   color=adata.uns['prediction_colors'][idx])\nfig.tight_layout()\n\n\n\n\n\nadata.write('../results/07_niakan_mouse_treatment_query.h5ad')\nlvae_q.save('../results/07_query', overwrite=True, save_anndata=True)"
  },
  {
    "objectID": "notebooks/01_mouse_loadAndIntegrate.html#figures-and-stuff",
    "href": "notebooks/01_mouse_loadAndIntegrate.html#figures-and-stuff",
    "title": "Niakan mouse treatment (follow-up on 06 analysis)",
    "section": "4 4. Figures and stuff",
    "text": "4 4. Figures and stuff\n\nlvae = scvi.model.SCANVI.load('../results/07_mouse_scanvi_ns_15/')\nlvae.adata.obs['prediction'] = lvae.predict()\n\nlvae_q = scvi.model.SCANVI.load('../results/07_query/')\nlvae_q.adata.obs['stage'] = lvae_q.adata.obs.prediction.str.split('-', expand=True)[1].values\n\nTrainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scvi/model/base/_utils.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(model_path, map_location=map_location)\nTrainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scvi/model/base/_utils.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(model_path, map_location=map_location)\n\n\nINFO     File ../results/07_mouse_scanvi_ns_15/model.pt already downloaded                                         \nINFO     File ../results/07_query/model.pt already downloaded                                                      \n\n\n\n4.1 4.1. Remove TE cells\n\nadata_sub = lvae_q.adata[~lvae_q.adata.obs.prediction.str.endswith('TE')].copy()\n\n\nax = sc.pl.pca(adata_sub, color = ['prediction', 'entropy', 'Treatment'], wspace=0.2, vmax=1, return_fig=True)\nax.savefig('../figures/07_pca.pdf')\n\n\n\n\n\n\n4.2 4.2. Integration with mouse\n\nimport anndata\nfrom scvi.model.utils import mde\n\n\ncombined = anndata.concat([lvae.adata, lvae_q.adata])\ncombined.obs['dataset'] = 'Reference v1.1'\ncombined.obs.loc[lvae_q.adata.obs_names, 'dataset'] = 'Simon et al., 2024'\n\ncombined.obsm['X_scANVI'] = np.concatenate([lvae.get_latent_representation(), lvae_q.get_latent_representation()])\n\ncombined\n\nAnnData object with n_obs × n_vars = 2189 × 3000\n    obs: 'batch', 'experiment', 'technology', 'stage', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', '_scvi_batch', '_scvi_labels', 'ct_custom', 'prediction', 'dataset'\n    obsm: 'X_scANVI'\n    layers: 'counts'\n\n\n\nsc.pp.neighbors(combined, use_rep='X_scANVI')\nsc.tl.draw_graph(combined)\nsc.tl.umap(combined)\n\ncombined.obsm['X_mde'] = mde(combined.obsm['X_scANVI'], init=\"random\")\n\nTrainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\n\n\nINFO     Using cuda:0 for `pymde.preserve_neighbors`.                                                              \n\n\n\nax = sc.pl.umap(combined, color=['dataset', 'prediction', 'stage'], frameon=False, wspace=0.25, return_fig=True)\nax.savefig('../figures/07_umap.pdf')\n\n\n\n\n\nax = sc.pl.draw_graph(combined, color=['dataset', 'prediction', 'stage'], frameon=False, wspace=0.2, return_fig=True)\nax.savefig('../figures/07_directed_graph.pdf')\n\n\n\n\n\nax = sc.pl.embedding(combined, basis='X_mde', color=['dataset', 'prediction', 'stage'], frameon=False, wspace=0.2, return_fig=True)\nax.savefig('../figures/07_mde.pdf')\n\n\n\n\n\nsc.tl.diffmap(combined)\nsc.tl.paga(combined, groups='prediction')\nsc.pl.paga(combined, color=['prediction'], frameon=False, fontoutline=True)\nsc.tl.draw_graph(combined, init_pos='paga', n_jobs=10)\n\n\n\n\n\nax = sc.pl.draw_graph(combined, color=['dataset', 'prediction', 'stage'], frameon=False, wspace=0.2, return_fig=True)\nax.savefig('../figures/07_directed_graph_with_paga.pdf')\n\n\n\n\n\n\n4.3 4.3. CAT analysis\n\nlvae.adata.raw.to_adata().write('../data/processed/07_mouse_ref_1.1.h5ad')\n\n\ntmp_adata = adata.raw.to_adata()\nsc.pp.filter_genes(tmp_adata, min_cells=3)\ntmp_adata[tmp_adata.obs.Treatment == \"Ulixertinib\"].write('../data/processed/07_simon_et_al.h5ad')\n\nsbatch 07_CAT.sbatch\nFrom CAT analysis, we can conclude that the predicted E4.5 EPI Ulix cells are E3.5-ICM and E3.75-ICM like cells. For more info, see the file ../results/07_CAT/Simon_REF_euclidean.html\n\n\n4.4 4.5. Counts\n\ndf = sc.metrics.confusion_matrix('Treatment', 'prediction', adata_sub.obs, normalize=False)\ndf.to_csv('../results/07_treatment_prediction_counts.csv')\n\ndisplay(df)\n\n\n\n\n\n\n\nprediction\nE3.5-ICM\nE3.5-PrE\nE4.5-EPI\nE4.5-PrE\n\n\nTreatment\n\n\n\n\n\n\n\n\nDMSO\n8\n4\n32\n29\n\n\nUlixertinib\n21\n0\n87\n0"
  },
  {
    "objectID": "notebooks/01_mouse_loadAndIntegrate.html#differentially-expressed-genes",
    "href": "notebooks/01_mouse_loadAndIntegrate.html#differentially-expressed-genes",
    "title": "Niakan mouse treatment (follow-up on 06 analysis)",
    "section": "5 5. Differentially expressed genes",
    "text": "5 5. Differentially expressed genes\n\ncombined.obs['treatment'] = 'ATLAS_WT'\ncombined.obs.loc[lvae_q.adata.obs_names, 'treatment'] = lvae_q.adata.obs.Treatment\n\n\n5.1 5.1. All EPI, ICM & PrE cells treated vs untreated\n\nepi_icm_pre_cells = combined.obs.query('batch == \"NIAKAN_1\" & prediction.str.contains(\"ICM|EPI|PrE\")').index.tolist()\nsubset = combined[epi_icm_pre_cells].copy()\n\nsc.tl.rank_genes_groups(subset, groupby='treatment')\nsc.get.rank_genes_groups_df(subset, group='Ulixertinib').to_csv('../results/07_Ulixertinib_vs_DMSO_EPI_ICM_PrE.csv')\n\n\n5.1.1 5.2. Only EPI & ICM cells treated vs untreated\n\nepi_icm_cells = combined.obs.query('batch == \"NIAKAN_1\" & prediction.str.contains(\"ICM|EPI\")').index.tolist()\nsubset = combined[epi_icm_cells].copy()\n\nsc.tl.rank_genes_groups(subset, groupby='treatment')\nsc.get.rank_genes_groups_df(subset, group='Ulixertinib').to_csv('../results/07_Ulixertinib_vs_DMSO_EPI_ICM.csv')\n\n\n\n5.1.2 5.3. EPI & ICM cells treated vs published (called as E3.5 ICM. E3.5 EPI, E4.5 EPI)\n\nepi_icm_cells = combined.obs.query('batch == \"NIAKAN_1\" & treatment == \"Ulixertinib\" & prediction.str.contains(\"ICM|EPI\")').index.tolist()\natlas_epi_icm = combined.obs.query('batch != \"NIAKAN_1\" & prediction.isin([\"E3.5-ICM\", \"E3.5-EPI\", \"E4.5-EPI\"])').index.tolist()\n\nsubset = combined[epi_icm_cells + atlas_epi_icm].copy()\nsc.tl.rank_genes_groups(subset, groupby='treatment')\nsc.get.rank_genes_groups_df(subset, group='Ulixertinib').to_csv('../results/07_Ulixertinib_vs_Atlas_EPI_ICM.csv')\n\n\n\n5.1.3 5.4. EPI & ICM cells untreated vs published (called as E3.5 ICM. E3.5 EPI, E4.5 EPI)\n\nepi_icm_cells = combined.obs.query('batch == \"NIAKAN_1\" & treatment == \"DMSO\" & prediction.str.contains(\"ICM|EPI\")').index.tolist()\natlas_epi_icm = combined.obs.query('batch != \"NIAKAN_1\" & prediction.isin([\"E3.5-ICM\", \"E3.5-EPI\", \"E4.5-EPI\"])').index.tolist()\n\nsubset = combined[epi_icm_cells + atlas_epi_icm].copy()\nsc.tl.rank_genes_groups(subset, groupby='treatment')\nsc.get.rank_genes_groups_df(subset, group='DMSO').to_csv('../results/07_DMSO_vs_Atlas_EPI_ICM.csv')"
  },
  {
    "objectID": "notebooks/04_human_integrationPlots.html",
    "href": "notebooks/04_human_integrationPlots.html",
    "title": "Niakan - Plots for cell type predictions",
    "section": "",
    "text": "!which pip\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.1.5/bin/pip\n%matplotlib inline\n%load_ext autoreload\n%autoreload 2\n\nimport scvi\nimport anndata\nimport numpy as np\nimport scanpy as sc\nimport seaborn as sns\nfrom scvi.model.utils import mde\nimport matplotlib.pyplot as plt\nimport pandas as pd\nplt.rcParams['svg.fonttype'] = 'none'\n\nct_colors = {\n    'Prelineage': '#7985A5',\n    '8C_3.0': '#028A46',\n    'Morula_4.0': '#657cbd',\n    'Inner Cell Mass': '#F6C445',\n    'Primitive Endoderm': '#D05B61',\n    'Epiblast_6.0': '#d6b2ca',\n    'Epiblast_7.0': '#c38db1',\n    'Late epiblast': '#aa5c8f',\n    'Trophectoderm_5.0': '#cddff0',\n    'Trophectoderm_6.0': '#bdd4eb',\n    'Trophectoderm_7.0': '#acc9e6',\n    'Trophectoderm_8.0': '#9cbfe2',\n    'Trophectoderm_9.0': '#8bb4dd',\n    'Trophectoderm_10.0': '#5a94ce',\n    'Unknown': '#F1BD93',\n}\nENSG_SYMBOL_df = pd.read_table('../results/GRCh38.110.ENSG_to_SYMBOL.csv', delimiter=',').set_index('ensembl')"
  },
  {
    "objectID": "notebooks/04_human_integrationPlots.html#human",
    "href": "notebooks/04_human_integrationPlots.html#human",
    "title": "Niakan - Plots for cell type predictions",
    "section": "1 Human",
    "text": "1 Human\n\n1.1 Human UMAP\n\nniakan_adata = sc.read_h5ad(\"../results/niakan_08.withPredictions.adata.h5ad\")\nniakan_adata.uns['prediction_colors'] = [ct_colors[x] for x in niakan_adata.obs.prediction.cat.categories]\n\nniakan_adata\n\nAnnData object with n_obs × n_vars = 89 × 3000\n    obs: 'sample', 'fastq_1', 'fastq_2', 'treatment', 'batch', 'experiment', 'technology', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', '_scvi_batch', 'ct', '_scvi_labels', 'prediction', 'entropy'\n    var: 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n    uns: '_scvi_manager_uuid', '_scvi_uuid', 'batch_colors', 'hvg', 'log1p', 'neighbors', 'pca', 'prediction_colors', 'treatment_colors', 'umap'\n    obsm: 'X_pca', 'X_scANVI', 'X_umap'\n    layers: 'counts'\n    obsp: 'connectivities', 'distances'\n\n\n\n# plt.rcParams['figure.figsize'] = [5, 4]\nax = sc.pl.umap(niakan_adata, color=['prediction', 'treatment', 'entropy'], s=120, wspace=0.35, return_fig = True)\nax.savefig('../figures/niakan_12_UMAP_prediction_treatment_entropy.pdf', bbox_inches = 'tight')\n\n\n\n\n\n# ax = sc.pl.umap(niakan_adata, color=['entropy'], s=120, return_fig = True)\n\n\ncmtx = sc.metrics.confusion_matrix('treatment', 'prediction', normalize=True, data=niakan_adata.obs)\ncolumn_order = ['Inner Cell Mass','Epiblast_6.0','Epiblast_7.0','Late epiblast','Primitive Endoderm','Trophectoderm_6.0','Trophectoderm_7.0','Trophectoderm_8.0','Trophectoderm_9.0']\n\nplt.rcParams['figure.figsize'] = [10, 4]\nax = cmtx[column_order].plot(kind='barh',legend=True, stacked=True, color=ct_colors)\nax.figure.savefig('../figures/niakan_12_Proportions_withLegend.pdf')\n\n\n\n\n\nax = cmtx[column_order].plot(kind='barh',legend=False, stacked=True, color=ct_colors)\nax.figure.savefig('../figures/niakan_12_Proportions_withoutLegend.pdf')\n\n\n\n\n\n\n1.2 Human heatmaps\n\nniakan_adata = sc.read_h5ad(\"../results/11_niakan_adata_combined_notLengthNormalised_withPredictions.h5ad\")\n\n\n# remove mitochondrial genes\nniakan_adata = niakan_adata[:, niakan_adata.var[~niakan_adata.var.gene_symbol.str.startswith('MT-')].index].copy()\n# remove ribosomal genes\nniakan_adata = niakan_adata[:, niakan_adata.var[~niakan_adata.var.gene_symbol.str.startswith(('RPS', 'RPL'))].index].copy()\n\n\nsc.pp.normalize_total(niakan_adata,target_sum=10_000)\nsc.pp.log1p(niakan_adata)\nniakan_adata.raw = niakan_adata\n\n\nniakan_adata.var['gene'] = niakan_adata.var['gene_symbol'].to_list()\nniakan_adata.var = niakan_adata.var.set_index('gene')\n\n\nniakan_adata.var_names_make_unique()\n\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/anndata/utils.py:260: UserWarning: Suffix used (-[0-9]+) to deduplicate index values may make index values difficult to interpret. There values with a similar suffixes in the index. Consider using a different delimiter by passing `join={delimiter}`Example key collisions generated by the make_index_unique algorithm: ['SNORD116-1', 'SNORD116-2', 'SNORD116-3', 'SNORD116-4', 'SNORD116-5']\n  warnings.warn(\n\n\n\nTE_list = ['GATA2','GATA3','AMOT','TEAD4','YAP1']\nPrE_list = ['PDGFRA','OTX2','SOX17','GATA4','GATA6','HNF4A','COL4A1','COL4A2','NANOG','POU5F1']\ncRAF_plusTF_responsive_list = ['SPRY4','DUSP6','EGR1','HAS3', 'MYC','DUSP5','ETV5', 'ETV4', 'ETV1', 'JUN',  'LEFTY1', 'NANOG', 'SOX2','POU5F1', 'KLF4', 'GATA4','GATA6','SOX17']\n\n\nsc.pl.clustermap(niakan_adata[niakan_adata.obs.prediction.str.contains('Trophectoderm'),niakan_adata.var.gene_symbol.isin(TE_list)],\n    obs_keys='treatment',\n    z_score=1,\n    cmap=\"vlag\",\n    center=0,\n    use_raw = False,\n    save='12_niakan_human_heatmap_for_TE.pdf'\n)\n\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scanpy/plotting/_utils.py:471: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n\n\nWARNING: saving figure to file figures/clustermap12_niakan_human_heatmap_for_TE.pdf\n\n\n\n\n\n\nsc.pl.clustermap(niakan_adata[niakan_adata.obs.prediction.str.contains('Primitive Endoderm'),niakan_adata.var.gene_symbol.isin(cRAF_plusTF_responsive_list)],\n    obs_keys='treatment',\n    cmap=\"vlag\",\n    center=0,\n    use_raw = False,\n    save='12_niakan_human_heatmap_for_PrE.pdf'\n)\n\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scanpy/plotting/_utils.py:471: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n\n\nWARNING: saving figure to file figures/clustermap12_niakan_human_heatmap_for_PrE.pdf\n\n\n\n\n\n\nsc.pl.clustermap(niakan_adata[niakan_adata.obs.prediction.str.contains('Epiblast'),niakan_adata.var.gene_symbol.isin(cRAF_plusTF_responsive_list)],\n    obs_keys='treatment',\n    cmap=\"vlag\",\n    center=0,\n    use_raw = False,\n    save='12_niakan_human_heatmap_for_EPI.pdf'\n)\n\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scanpy/plotting/_utils.py:471: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n  adata.uns[value_to_plot + \"_colors\"] = colors_list\n\n\nWARNING: saving figure to file figures/clustermap12_niakan_human_heatmap_for_EPI.pdf\n\n\n\n\n\n\n\n1.3 Integration\n\nniakan_adata = sc.read_h5ad(\"../results/niakan_08.withPredictions.adata.h5ad\")\nlvae = scvi.model.SCANVI.load('../../proks-salehin-et-al-v2/results/100_human_integration/scanvi_ns_15/')\n\nTrainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scvi/model/base/_utils.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(model_path, map_location=map_location)\n\n\nINFO     File ../../proks-salehin-et-al-v2/results/100_human_integration/scanvi_ns_15/model.pt already downloaded  \n\n\n\n# scvi.model.SCANVI.prepare_query_anndata(niakan_adata, lvae)\n# lvae_q = scvi.model.SCANVI.load_query_data(niakan_adata, lvae)\n# lvae.adata.obs['prediction'] = lvae.predict()\n# lvae_q.train(max_epochs=20, plan_kwargs=dict(weight_decay=0.0), check_val_every_n_epoch=10, early_stopping=True)\n# lvae.adata.obsm[\"X_scANVI\"] = lvae.get_latent_representation()\n# niakan_adata.obsm[\"X_scANVI\"] = lvae_q.get_latent_representation()\n# niakan_adata.obs['prediction'] = lvae_q.predict()\n# niakan_adata.obs['entropy'] = 1 - lvae_q.predict(soft=True).max(axis=1)\n# niakan_adata.obsm['X_cell_prbs'] = lvae_q.predict(soft=True)\n\n# lvae_q.save('../results/12_niakan_human_query', save_anndata=True)\n\n\nlvae_q = scvi.model.SCANVI.load('../results/12_niakan_human_query')\nlvae.adata.obs['prediction'] = lvae.predict()\nlvae.adata.obsm[\"X_scANVI\"] = lvae.get_latent_representation()\nniakan_adata.obsm[\"X_scANVI\"] = lvae_q.get_latent_representation()\nniakan_adata.obs['prediction'] = lvae_q.predict()\nniakan_adata.obs['entropy'] = 1 - lvae_q.predict(soft=True).max(axis=1)\nniakan_adata.obsm['X_cell_prbs'] = lvae_q.predict(soft=True)\n\nTrainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scvi/model/base/_utils.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(model_path, map_location=map_location)\n\n\nINFO     File ../results/12_niakan_human_query/model.pt already downloaded                                         \n\n\n\nmerged_adata = anndata.concat([lvae.adata.copy(), niakan_adata])\nmerged_adata.obs['this_study'] = merged_adata.obs['experiment'] == 'Simon et al, 2024'\nmerged_adata.obs.prediction = merged_adata.obs.prediction.astype('category')\nmerged_adata.obs.prediction = merged_adata.obs.prediction.cat.reorder_categories(['Prelineage', '8C_3.0', 'Morula_4.0', 'Inner Cell Mass', 'Epiblast_6.0', 'Epiblast_7.0', 'Late epiblast', 'Primitive Endoderm', 'Trophectoderm_5.0', 'Trophectoderm_6.0', 'Trophectoderm_7.0', 'Trophectoderm_8.0', 'Trophectoderm_9.0', 'Trophectoderm_10.0'], ordered=True)\nmerged_adata.uns['prediction_colors'] = [ct_colors[ct] for ct in merged_adata.obs.prediction.cat.categories]\n\nmerged_adata.obs['treatment'] = None\nmerged_adata.obs.loc[merged_adata.obs_names.str.contains('Ulix'), 'treatment'] = 'Ulix'\nmerged_adata.obs.loc[merged_adata.obs_names.str.contains('DMSO'), 'treatment'] = 'DMSO'\n\n\nsc.pp.neighbors(merged_adata, use_rep=\"X_scANVI\", n_neighbors = 15, metric='euclidean')\nsc.tl.umap(merged_adata, min_dist=0.5)\nsc.tl.draw_graph(merged_adata)\n\n\nax = sc.pl.umap(merged_adata, color=['batch', 'prediction', 'this_study', 'treatment'], ncols=2, wspace=0.4, return_fig=True)\nax.savefig('../figures/12_niakan_human_integration_umap.pdf')\n\n\n\n\n\n\nax = sc.pl.draw_graph(merged_adata,color=['batch', 'prediction', 'this_study', 'treatment'], ncols=2, wspace=0.4, return_fig=True)\nax.savefig('../figures/12_niakan_human_integration_FA.pdf')"
  },
  {
    "objectID": "notebooks/04_human_integrationPlots.html#pseudotime",
    "href": "notebooks/04_human_integrationPlots.html#pseudotime",
    "title": "Niakan - Plots for cell type predictions",
    "section": "2 Pseudotime",
    "text": "2 Pseudotime\n\nimport scFates as scf\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nlvae = scvi.model.SCANVI.load('../../proks-salehin-et-al-v2/results/100_human_integration/scanvi_ns_15/')\nlvae.adata.obs['dataset'] = 'Reference'\nlvae.adata.obs['prediction'] = lvae.predict()\nlvae.adata.obsm[\"X_scANVI\"] = lvae.get_latent_representation()\n\nlvae_q = scvi.model.SCANVI.load('../results/12_niakan_human_query')\nlvae.adata.obs['dataset'] = 'Simon et al, 2024'\nlvae_q.adata.obsm[\"X_scANVI\"] = lvae_q.get_latent_representation()\n\nINFO     File ../../proks-salehin-et-al-v2/results/100_human_integration/scanvi_ns_15/model.pt already downloaded  \nINFO     File ../results/12_niakan_human_query/model.pt already downloaded                                         \n\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scvi/model/base/_utils.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(model_path, map_location=map_location)\n/projects/dan1/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scvi/model/base/_utils.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(model_path, map_location=map_location)\n\n\n\nmerged_adata = anndata.concat([lvae.adata.copy(), lvae_q.adata.copy()])\nmerged_adata.obs['this_study'] = merged_adata.obs['experiment'] == 'Simon et al, 2024'\nmerged_adata.obs.prediction = merged_adata.obs.prediction.astype('category')\nmerged_adata.obs.prediction = merged_adata.obs.prediction.cat.reorder_categories(['Prelineage', '8C_3.0', 'Morula_4.0', 'Inner Cell Mass', 'Epiblast_6.0', 'Epiblast_7.0', 'Late epiblast', 'Primitive Endoderm', 'Trophectoderm_5.0', 'Trophectoderm_6.0', 'Trophectoderm_7.0', 'Trophectoderm_8.0', 'Trophectoderm_9.0', 'Trophectoderm_10.0'], ordered=True)\nmerged_adata.uns['prediction_colors'] = [ct_colors[ct] for ct in merged_adata.obs.prediction.cat.categories]\n\nmerged_adata.obs['treatment'] = 'None'\nmerged_adata.obs.loc[merged_adata.obs_names.str.contains('Ulix'), 'treatment'] = 'Ulix'\nmerged_adata.obs.loc[merged_adata.obs_names.str.contains('DMSO'), 'treatment'] = 'DMSO'\n\n\nmerged_adata = merged_adata[merged_adata.obs.prediction.isin(['Morula_4.0', 'Inner Cell Mass','Epiblast_6.0','Epiblast_7.0','Late epiblast','Primitive Endoderm'])].copy()\n\n\nsc.pp.neighbors(merged_adata, use_rep=\"X_scANVI\")\nsc.tl.umap(merged_adata)\nsc.tl.diffmap(merged_adata)\n\nsc.tl.paga(merged_adata, groups='prediction')\nsc.pl.paga(merged_adata, color='prediction', frameon=False, fontoutline=True)\nsc.tl.draw_graph(merged_adata, init_pos='paga')\n\n2024-12-12 11:57:22.994547: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n\n\n\n\n\n\nsc.pl.draw_graph(merged_adata, color=['prediction'], frameon=False, ncols=2)\n\n\n\n\n\nmerged_adata.uns['iroot'] = np.flatnonzero(merged_adata.obs['prediction']  == 'Morula_4.0')[0]\nsc.tl.dpt(merged_adata)\n\n\nsc.pl.draw_graph(merged_adata, color=['dpt_pseudotime', 'prediction'], frameon=False, ncols=2)\n\n\n\n\n\nsc.pp.neighbors(merged_adata, use_rep=\"X_scANVI\")\nsc.tl.draw_graph(merged_adata)\n\n\nsc.pl.draw_graph(merged_adata, color=['prediction'])\n\n\n\n\n\nsig = scf.tl.explore_sigma(merged_adata,\n                         Nodes=20,\n                         use_rep=\"X_draw_graph_fa\",\n                         sigmas=[1000,500,400,300,200,100,50,10,1],\n                         seed=42,plot=True)\n\n\n\n\n\nscf.tl.tree(merged_adata,\n            Nodes=20,\n            use_rep=\"X_draw_graph_fa\",\n            method=\"ppt\",\n            ppt_nsteps=10,\n            ppt_sigma=sig,\n            ppt_lambda=100,\n            seed=42)\n\ninferring a principal tree --&gt; parameters used \n    20 principal points, sigma = 500, lambda = 100, metric = euclidean\n    fitting:   0%|          | 0/10 [00:00&lt;?, ?it/s]    fitting: 100%|██████████| 10/10 [00:00&lt;00:00, 22.83it/s]\n    not converged (error: 0.06862519665918461)\n    finished (0:00:00) --&gt; added \n    .uns['ppt'], dictionnary containing inferred tree.\n    .obsm['X_R'] soft assignment of cells to principal points.\n    .uns['graph']['B'] adjacency matrix of the principal points.\n    .uns['graph']['F'] coordinates of principal points in representation space.\n\n\n\nscf.pl.graph(merged_adata)\n\n\n\n\n\nscf.tl.root(merged_adata, 3)\n\nnode 3 selected as a root --&gt; added\n    .uns['graph']['root'] selected root.\n    .uns['graph']['pp_info'] for each PP, its distance vs root and segment assignment.\n    .uns['graph']['pp_seg'] segments network information.\n\n\n\nscf.tl.pseudotime(merged_adata,n_jobs=10,n_map=10,seed=42)\n\nprojecting cells onto the principal graph\n    mappings:   0%|          | 0/10 [00:00&lt;?, ?it/s]    mappings: 100%|██████████| 10/10 [00:29&lt;00:00,  2.93s/it]\n    finished (0:00:29) --&gt; added\n    .obs['edge'] assigned edge.\n    .obs['t'] pseudotime value.\n    .obs['seg'] segment of the tree assigned.\n    .obs['milestones'] milestone assigned.\n    .uns['pseudotime_list'] list of cell projection from all mappings.\n\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid = os.fork()\n\n\n\nscf.pl.trajectory(merged_adata)\n\n\n\n\n\nmerged_adata.obs['t_scaled'] = MinMaxScaler().fit_transform(merged_adata.obs['t'].values.reshape(-1, 1)).flatten()\n\n\nmerged_adata.uns['treatment_colors'] = ['tab:blue', 'lightgrey', 'tab:orange']\n\n\nax = sc.pl.draw_graph(merged_adata, color=['prediction', 'treatment', 'dpt_pseudotime', 't_scaled'], frameon=False, ncols=2, cmap='viridis', wspace=0.3, return_fig=True)\nax.savefig('../figures/12_niakan_human_pseudotime.pdf')\n\n\n\n\n\n# df = pd.DataFrame({\n#     'pseudotime': merged_adata.obs.t_scaled.to_numpy(),\n#     'treatment': merged_adata.obs.treatment.to_numpy(),\n#     'treatment_codes': merged_adata.obs.treatment.cat.codes.to_numpy()\n# }).sort_values(by='pseudotime')\n\n# fig, ax = plt.subplots(2,1,figsize=(10,2.5))\n# sns.heatmap(df[['pseudotime']].T, cmap='viridis', cbar=True, xticklabels=False, ax=ax[0])\n# sns.heatmap(df[['treatment_codes']].T, cmap=merged_adata.uns['treatment_colors'], cbar=True, xticklabels=False, ax=ax[1])\n# fig.savefig('../figures/12_niakan_human_pseudotime_treatment.pdf')\n\n\nadata = merged_adata[merged_adata.obs.prediction.isin(['Inner Cell Mass','Epiblast_6.0','Epiblast_7.0','Late epiblast'])]\nadata = adata[adata.obs.sort_values(by='t_scaled').index].copy()\n\n# df = adata.to_df()\ndf = adata.raw.to_adata().to_df()\n# df.columns = lvae.adata.var.symbol.values\ndf.columns = ENSG_SYMBOL_df.loc[df.columns.values,'symbol'].values\ndf = (df - df.min()) / (df.max() - df.min())\ndf = df\\\n    .assign(predictions=adata.obs.prediction.cat.codes.to_numpy())\\\n    .assign(pseudotime=adata.obs.t_scaled.to_numpy())\\\n    .assign(treatment=adata.obs.treatment)\\\n    .assign(treatment_codes=adata.obs.treatment.cat.codes.to_numpy())\\\n    .assign(DMSO=adata.obs.treatment == 'DMSO')\\\n    .assign(Ulixertinib=adata.obs.treatment == 'Ulix')\ndf['ps_bins'] = pd.cut(df.pseudotime, bins=np.arange(0, 1.1, 0.1))\n\n\nfig, ax = plt.subplots(9,1,figsize=(9,2.5))\nfor idx, gene in enumerate(['SOX2', 'NANOG', 'FGF4', 'KLF17']):\n    sns.heatmap(df[[gene]].T, cmap='Reds', cbar=False, xticklabels=False, ax=ax[idx])\nsns.heatmap(df[['DMSO']].T, cbar=False, cmap=['lightgrey', 'tab:blue'], xticklabels=False, ax=ax[4])\nsns.heatmap(df[['Ulixertinib']].T, cmap=['lightgrey', 'tab:orange'], cbar=False, xticklabels=False, ax=ax[5])\nsns.heatmap(df[['treatment_codes']].T, cbar=False, cmap=list(adata.uns['treatment_colors']), xticklabels=False, ax=ax[6])\nsns.heatmap(df[['predictions']].T, cbar=False, cmap=adata.obs.prediction.map(ct_colors).cat.categories.tolist(), xticklabels=False, ax=ax[7])\nsns.heatmap(df[['pseudotime']].T, cmap='viridis', cbar=False, xticklabels=False, ax=ax[8])\nfor ax_ in ax:\n    ax_.tick_params(axis='y', rotation=0)\nfig.suptitle('Trajectory from ICM to EPI')\nfig.savefig('../figures/12_niakan_human_pseudotime_ICM_EPI.pdf', bbox_inches='tight')\n\n\n\n\n\nax = (pd.crosstab(df.ps_bins, df.treatment, normalize='index') * 100).plot.bar(color=['tab:blue', 'lightgrey', 'tab:orange'], title='Treated cells over pseudotime', xlabel='Binned pseudotime', ylabel='% of cells')\nax.figure.savefig('../figures/12_niakan_human_pseudotime_ICM_EPI_treatment.pdf', bbox_inches='tight')"
  },
  {
    "objectID": "notebooks/04_mouse_integrationPlots.html",
    "href": "notebooks/04_mouse_integrationPlots.html",
    "title": "Niakan - Plots for cell type predictions",
    "section": "",
    "text": "!which pip\n\n~/projects/data/Brickman/conda/envs/scvi-1.1.5/bin/pip\n%matplotlib inline\n%load_ext autoreload\n%autoreload 2\n\nimport scvi\nimport anndata\nimport numpy as np\nimport pandas as pd\nimport scanpy as sc\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.rcParams['svg.fonttype'] = 'none'\n\nlineage_colors = {\n    'Zygote': '#7985A5',\n    '2C': '#B3C81E',\n    '4C': '#67BB30',\n    '8C': '#028A46',\n    '16C': '#657cbd',\n    'ICM': '#F6C445',\n    'TE': '#5a94ce',\n    'EPI': '#B46F9C',\n    'PrE': '#D05B61'\n}\n\nmouse_ct_colors = {\n    'Zygote': '#7985A5',\n    '2C': '#B3C81E',\n    '4C': '#67BB30',\n    '8C': '#028A46',\n    '16C': '#657cbd',\n    'E3.25-ICM': '#fadc8f',\n    'E3.25-TE': '#5185b9',\n    'E3.5-ICM': '#f8d06a',\n    'E3.5-TE': '#7ba9d8',\n    'E3.5-EPI': '#c38cb0',\n    'E3.5-PrE': '#d97c81',\n    'E3.75-ICM': '#F6C445',\n    'E4.5-TE': '#5a94ce',\n    'E4.5-EPI': '#B46F9C',\n    'E4.5-PrE': '#D05B61',\n    'Unknown': 'lightgrey'\n}\nimport sys; sys.path.append(\"../scripts/\")\nfrom helpers import normalize_smartseq\nmouse = sc.read_h5ad(\"/home/fdb589/Brickman/projects/proks-salehin-et-al-2023/data/processed/01_mouse_reprocessed.h5ad\")\nmouse.obs['ct_custom'] = mouse.obs.ct.replace('E3.75-ICM', 'Unknown')\n\n# sc.pp.highly_variable_genes(mouse, flavor=\"cell_ranger\", n_top_genes=3_000, batch_key=\"batch\", subset=True)\nsc.pp.highly_variable_genes(mouse, flavor=\"seurat_v3\", n_top_genes=3_000, batch_key=\"batch\", layer='counts', subset=True)\nmouse.obs['batch_og'] = mouse.obs['batch']\nmouse.obs['batch'] = mouse.obs.batch\n# mouse.obs['batch'] = mouse.obs.technology.cat.codes.astype(str) + \"_\" + mouse.obs.batch.cat.codes.astype(str)\n# mouse.obs['batch'] = mouse.obs.technology.cat.codes.astype(str) + \"_\" + mouse.obs.experiment.cat.codes.astype(str) + mouse.obs.batch.cat.codes.astype(str)\n\nscvi.model.SCVI.setup_anndata(mouse, layer=\"counts\", batch_key=\"batch\")\nvae = scvi.model.SCVI(mouse, n_layers=2, gene_likelihood='nb')\nvae.train(max_epochs=400, early_stopping=True)\n\nlvae = scvi.model.SCANVI.from_scvi_model(vae, adata=mouse, labels_key=\"ct_custom\", unlabeled_category=\"Unknown\")\nlvae.train(max_epochs=20, n_samples_per_label=15)\n\nmouse.obsm['X_scVI'] = vae.get_latent_representation()\nmouse.obsm['X_scANVI'] = lvae.get_latent_representation()\nmouse.obs['predictions'] = lvae.predict()\nmouse.obs['predictions'] = mouse.obs['predictions'].astype('category')\nmouse.obs['predictions_stages'] = [x.split('-')[-1] for x in mouse.obs.predictions]\nmouse.obs['predictions_stages'] = mouse.obs['predictions_stages'].astype('category')\n\nmouse.uns['predictions_colors'] = [mouse_ct_colors[ct] for ct in mouse.obs.predictions.cat.categories]\nmouse.uns['predictions_stages_colors'] = [lineage_colors[ct] for ct in mouse.obs.predictions_stages.cat.categories]\nmouse.obs.query('ct == \"E3.75-ICM\"')['predictions'].value_counts()\nsc.pp.neighbors(mouse, use_rep='X_scVI')\nsc.tl.umap(mouse)\nsc.tl.diffmap(mouse)\nsc.tl.paga(mouse, groups='predictions')\nsc.pl.paga(mouse, color=['predictions'], frameon=False, fontoutline=True)\nsc.tl.draw_graph(mouse, init_pos='paga', n_jobs=10)\nsc.pl.umap(mouse, color=['technology', 'predictions', 'predictions_stages'], wspace=0.3)\nsc.pl.draw_graph(mouse, color=['technology', 'predictions', 'predictions_stages'], wspace=0.3)\nmouse.obs.value_counts(['technology', 'predictions']).unstack().fillna(0)\nvae.save(\"../results/12_mouse/scvi\", overwrite=True, save_anndata=True)\nlvae.save(\"../results/12_mouse/scanvi_ns15\", overwrite=True, save_anndata=True)\n# ## Updated AI model\n\n# vae = scvi.model.SCVI.load(\"../../proks-salehin-et-al-2023/results/02_mouse_integration/scvi/\")\n\n# # Retraining\n# vae.adata.obs['ct_custom'] = vae.adata.obs.ct.replace('E3.75-ICM', 'Unknown')\n# lvae = scvi.model.SCANVI.from_scvi_model(vae, labels_key=\"ct_custom\", unlabeled_category=\"Unknown\")\n# lvae.train(n_samples_per_label=15)\n\n# # lvae.save(\"../results/12_mouse/scanvi_ns_15\", overwrite=True, save_anndata=True)"
  },
  {
    "objectID": "notebooks/04_mouse_integrationPlots.html#niakan-analysis",
    "href": "notebooks/04_mouse_integrationPlots.html#niakan-analysis",
    "title": "Niakan - Plots for cell type predictions",
    "section": "1 Niakan analysis",
    "text": "1 Niakan analysis\n\nGENE_LEN = '~/Brickman/shared/references/mus_musculus/ensembl/GRCm38_102/Mus_musculus_GRCm38_102_gene_length.txt'\n\n# adata = sc.read_h5ad(\"../data/external/niakan_et_al/mouse/mtx_conversions/combined_matrix.h5ad\")\nadata = sc.read_h5ad(\"../data/assays/SCR_MP_20241207/processed/combined_matrix.h5ad\")\nadata.obs['LIMS.ID'] = adata.obs['sample'].str.split('_', expand=True).iloc[:, 0]\nadata.obs = adata.obs.merge(pd.read_csv(\"../data/assays/SCR_MP_20241207/raw/Samples_LIMSID_Mouse.csv\"), \n                            left_on='sample', right_on='LIMS.ID', how='left').set_index(adata.obs_names)\nadata.obs['batch'] = 'NIAKAN_' + adata.obs['Plate.no'].astype(str)\nadata.obs['experiment'] = \"Simon et al, 2024\"\nadata.obs['technology'] = \"SMART-seq2\"\n\nadata = adata[~adata.obs['sample'].isin(['SIM5111A40', 'SIM5111A48'])]\nadata = adata[adata.obs.QC == \"Pass\"]\nadata = adata[~adata.obs.Treatment.isna()].copy()\n\nadata.var['mt'] = adata.var.gene_symbol.str.startswith('mt-')\nsc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n\nadata = adata[adata.obs.pct_counts_mt &lt; 25].copy()\n\nadata = normalize_smartseq(adata, GENE_LEN)\n\nadata.var['gene_id'] = adata.var_names\nadata.var_names = adata.var.gene_symbol.str.lower().values\nadata.var_names_make_unique()\n\nadata.layers[\"counts\"] = adata.X.copy()\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nadata.raw = adata\n\nsc.pp.highly_variable_genes(adata, flavor=\"cell_ranger\", n_top_genes=3_000, batch_key=\"batch\")\nsc.tl.pca(adata)\n\nsc.pl.pca(adata, color='Treatment')\ndisplay(adata.obs.Treatment.value_counts())\n\nadata.write('../results/12_niakan.mouse.h5ad')\n\n\n1.1 Prediction\n\nmouse_query = sc.read_h5ad('../results/12_niakan.mouse.h5ad')\ndel mouse_query.varm['PCs']\n\nlvae = scvi.model.SCANVI.load(\"../results/12_mouse/scanvi_ns15\")\n\nscvi.model.SCANVI.prepare_query_anndata(mouse_query, lvae)\nlvae_q = scvi.model.SCANVI.load_query_data(mouse_query, lvae)\nlvae_q.train(max_epochs=100, plan_kwargs=dict(weight_decay=0.0), check_val_every_n_epoch=10, early_stopping=True)\n\nTrainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scvi/model/base/_utils.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(model_path, map_location=map_location)\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/anndata/_core/merge.py:1362: UserWarning: Only some AnnData objects have `.raw` attribute, not concatenating `.raw` attributes.\n  warn(\nTrainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scvi/data/_manager.py:215: UserWarning: Missing labels key ct_custom. Filling in with unlabeled category Unknown.\n  field_registry[_constants._STATE_REGISTRY_KEY] = field.transfer_field(\nTrainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=223` in the `DataLoader` to improve performance.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=223` in the `DataLoader` to improve performance.\n\n\nINFO     File ../results/12_mouse/scanvi_ns15/model.pt already downloaded                                          \nINFO     Found 84.83333333333334% reference vars in query data.                                                    \nINFO     Training for 100 epochs.                                                                                  \nEpoch 91/100:  91%|█████████ | 91/100 [00:02&lt;00:00, 32.87it/s, v_num=1, train_loss_step=1.51e+4, train_loss_epoch=1.51e+4]\nMonitored metric elbo_validation did not improve in the last 45 records. Best score: 13435.031. Signaling Trainer to stop.\n\n\n\nmouse_query = sc.read_h5ad('../results/12_niakan.mouse.h5ad')\nmouse_query.obsm[\"X_scANVI\"] = lvae_q.get_latent_representation()\nmouse_query.obs['predictions'] = lvae_q.predict()\n\n# remove TE cells\n# mouse_query = mouse_query[~mouse_query.obs.predictions.str.contains('TE')].copy()\n\nmouse_query.obs['predictions'] = mouse_query.obs['predictions'].astype('category')\nmouse_query.obs['entropy'] = 1 - lvae_q.predict(soft=True).max(axis=1)\n\nmouse_query.uns['predictions_colors'] = [mouse_ct_colors[ct] for ct in mouse_query.obs.predictions.cat.categories]\n\n\n\n1.2 PCA/UMAP\n\nsc.pp.neighbors(mouse_query)\nsc.tl.pca(mouse_query)\nsc.tl.umap(mouse_query)\n\n\nplt.rcParams['figure.figsize'] = [5, 4]\nax = sc.pl.pca(mouse_query, color = ['predictions', 'entropy', 'Treatment'], wspace=0.25, vmax=1, return_fig=True)\nax.savefig('../figures/12_niakan_mouse_PCA.pdf')\n\nax = sc.pl.pca(mouse_query, color = [\n    'pou5f1', 'sox2', 'nanog',\n    'gata6', 'gata4', 'pdgfra',\n    'cdx2', 'hand1', 'krt7'\n    ], ncols=3, return_fig=True)\nax.savefig('../figures/12_niakan_mouse_PCA_markers.pdf')\n\n\n\n\n\n\n\n\nmarkers = {\n    'EPI': ['pou5f1', 'sox2', 'nanog'],\n    'PrE': ['gata6', 'gata4', 'pdgfra'],\n    'TE': ['cdx2', 'hand1', 'krt7']\n}\n\nax = sc.pl.dotplot(mouse_query, markers, groupby='Treatment', return_fig=True)\nax.savefig('../figures/12_niakan_mouse_dotplot_markers.pdf')\n\nax = sc.pl.matrixplot(adata, markers, groupby='Treatment', dendrogram=True, return_fig=True)\nax.savefig('../figures/12_niakan_mouse_matrixplot_markers.pdf')\n\nNameError: name 'adata' is not defined\n\n\n\n\n\n\n# plt.rcParams['figure.figsize'] = [5, 4]\n# ax = sc.pl.umap(mouse_query, color=['predictions'], s=120, return_fig = True)\n# ax.savefig('../figures/niakan_12_mouse_UMAP_01.pdf')\n\n\n# plt.rcParams['figure.figsize'] = [5, 4]\n# ax = sc.pl.umap(mouse_query, color=['Treatment'], s=120, return_fig = True)\n# ax.savefig('../figures/niakan_12_mouse_UMAP_02.pdf')\n\n\nplt.rcParams['figure.figsize'] = [10, 4]\ncmtx = sc.metrics.confusion_matrix('Treatment', 'predictions', normalize=True, data=mouse_query.obs)\nax = cmtx.plot(kind='barh',legend=True, stacked=True, color=mouse_ct_colors)\nax.legend(cmtx.columns, loc='center right', bbox_to_anchor=(1.17, 0.5), frameon=False)\nax.figure.savefig('../figures/niakan_12_mouse_Proportions_withLegend.pdf')\n\ndisplay(sc.metrics.confusion_matrix('Treatment', 'predictions', normalize=False, data=mouse_query.obs))\n\n\n\n\n\n\n\npredictions\nE3.5-ICM\nE3.5-TE\nE4.5-EPI\nE4.5-PrE\n\n\nTreatment\n\n\n\n\n\n\n\n\nDMSO\n0\n1\n17\n8\n\n\nUlixertinib\n2\n0\n24\n0\n\n\n\n\n\n\n\n\n\n\n\nmouse_query.write('../results/12_niakan.mouse.withPredictions.h5ad')"
  },
  {
    "objectID": "notebooks/04_mouse_integrationPlots.html#integration-with-mouse-dataset",
    "href": "notebooks/04_mouse_integrationPlots.html#integration-with-mouse-dataset",
    "title": "Niakan - Plots for cell type predictions",
    "section": "2 Integration with mouse dataset",
    "text": "2 Integration with mouse dataset\n\nlvae = scvi.model.SCANVI.load('../results/12_mouse/scanvi_ns15')\nlvae.adata.obs['predictions'] = lvae.predict()\n\nlvae_q.adata.obs['predictions'] = mouse_query.obs.predictions\n\nTrainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/fdb589/projects/data/Brickman/conda/envs/scvi- ...\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/scvi/model/base/_utils.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model = torch.load(model_path, map_location=map_location)\n\n\nINFO     File ../results/12_mouse/scanvi_ns15/model.pt already downloaded                                          \n\n\n\ncombined = anndata.concat([lvae.adata, lvae_q.adata])\ncombined.obs['dataset'] = 'Reference v1.1'\ncombined.obs.loc[lvae_q.adata.obs_names, 'dataset'] = 'Simon et al., 2024'\ncombined.obsm['X_scANVI'] = np.concatenate([lvae.get_latent_representation(), lvae_q.get_latent_representation()])\ncombined.obs.predictions = combined.obs.predictions.astype('category')\ncombined.obs['stage'] = [prediction.split('-')[-1] for prediction in combined.obs.predictions]\ncombined.obs.stage = combined.obs.stage.astype('category')\n\ncombined.uns['predictions_colors'] = [mouse_ct_colors[ct] for ct in combined.obs.predictions.cat.categories]\ncombined.uns['stage_colors'] = [lineage_colors[ct] for ct in combined.obs.stage.cat.categories]\n\ncombined.obs['highlight'] = combined.obs.predictions.astype(str)\ncombined.obs.loc[combined.obs.dataset == 'Simon et al., 2024', 'highlight'] = 'THIS_STUDY'\ncombined.obs['highlight'] = combined.obs['highlight'].astype('category')\ncombined.uns['highlight_colors'] = [mouse_ct_colors.get(ct, 'black') for ct in combined.obs.highlight.cat.categories]\n\n/home/fdb589/projects/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/anndata/_core/merge.py:1362: UserWarning: Only some AnnData objects have `.raw` attribute, not concatenating `.raw` attributes.\n  warn(\n\n\n\nsc.pp.neighbors(combined, use_rep='X_scANVI')\nsc.tl.draw_graph(combined)\nsc.tl.umap(combined)\nsc.tl.diffmap(combined)\nsc.tl.paga(combined, groups='predictions')\nsc.pl.paga(combined, color=['predictions'], frameon=False, fontoutline=True)\nsc.tl.draw_graph(combined, init_pos='paga', n_jobs=10)\n\n\n\n\n\nplt.rcParams['figure.figsize'] = [6, 4]\nax = sc.pl.umap(combined, color=['dataset', 'predictions', 'technology', 'stage'], ncols=2, wspace=0.3, return_fig=True)\nax.savefig('../figures/12_niakan_mouse_integration_umap.pdf')\n\n\n\n\n\nplt.rcParams['figure.figsize'] = [6, 4]\nax = sc.pl.draw_graph(combined, color=['dataset', 'predictions', 'technology', 'stage'], ncols=2, wspace=0.3, return_fig=True)\nax.savefig('../figures/12_niakan_mouse_integration_FA.pdf')\n\n\n\n\n\nplt.rcParams['figure.figsize'] = [6, 4]\nax = sc.pl.draw_graph(combined, color=['experiment', 'predictions', 'highlight', 'stage'], ncols=2, wspace=0.45, return_fig=True)\nax.savefig('../figures/12_niakan_mouse_integration_FA_2.pdf')\n\n\n\n\n\n2.1 Pseudotime\n\nmerged_subset = combined[combined.obs.predictions.str.contains('ICM|PrE|EPI')].copy()\nmerged_subset.obs['treatment'] = 'None'\nmerged_subset.obs.loc[merged_subset.obs_names.intersection(mouse_query.obs_names), 'treatment'] = mouse_query.obs.loc[merged_subset.obs_names.intersection(mouse_query.obs_names), 'Treatment'].values\nmerged_subset.uns['treatment_colors'] = ['tab:blue', 'lightgrey', 'tab:orange']\n\nmerged_subset\n\nAnnData object with n_obs × n_vars = 1325 × 3000\n    obs: 'batch', 'experiment', 'technology', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'ct_custom', '_scvi_batch', '_scvi_labels', 'predictions', 'dataset', 'stage', 'highlight', 'treatment'\n    uns: 'predictions_colors', 'stage_colors', 'highlight_colors', 'neighbors', 'draw_graph', 'umap', 'diffmap_evals', 'paga', 'predictions_sizes', 'dataset_colors', 'technology_colors', 'experiment_colors', 'treatment_colors'\n    obsm: 'X_scANVI', 'X_draw_graph_fa', 'X_umap', 'X_diffmap'\n    layers: 'counts'\n    obsp: 'distances', 'connectivities'\n\n\n\nsc.pp.neighbors(merged_subset, use_rep=\"X_scANVI\")\nsc.tl.umap(merged_subset)\nsc.tl.diffmap(merged_subset)\n\nsc.tl.paga(merged_subset, groups='predictions')\nsc.pl.paga(merged_subset, color='predictions', frameon=False, fontoutline=True)\nsc.tl.draw_graph(merged_subset, init_pos='paga')\n\n\n\n\n\nsc.pl.draw_graph(merged_subset, color=['stage', 'predictions', 'dataset'])\n\n\n\n\n\n# sc.pl.diffmap(merged_subset, color=['stage', 'predictions', 'dataset'])\n\nmerged_subset.obsm[\"X_diffmap_\"] = merged_subset.obsm[\"X_diffmap\"][:, 1:]\nsc.pl.embedding(merged_subset, \"diffmap_\", color=['stage', 'predictions', 'dataset'], wspace=0.2)\n\n\n\n\n\nmerged_subset.uns['iroot'] = np.flatnonzero(merged_subset.obs['predictions']  == 'E3.25-ICM')[0]\nsc.tl.dpt(merged_subset)\n\n\nax = sc.pl.embedding(merged_subset, \"diffmap_\", color=['predictions', 'treatment', 'stage', 'dpt_pseudotime'], ncols=2, wspace=0.25, return_fig=True)\nax.savefig('../figures/12_niakan_mouse_pseudotime_DC.pdf')\n# ax = sc.pl.draw_graph(merged_subset, color=['predictions', 'treatment', 'stage', 'dpt_pseudotime'], ncols=2, wspace=0.25, return_fig=True)\n\n\n\n\n\nadata = merged_subset[merged_subset.obs.predictions.str.contains('ICM|EPI')]\nadata = adata[adata.obs.sort_values(by='dpt_pseudotime').index].copy()\n\n\ndf = adata.to_df()\ndf = (df - df.min()) / (df.max() - df.min())\ndf = df\\\n    .assign(predictions=adata.obs.predictions.cat.codes.to_numpy())\\\n    .assign(pseudotime=adata.obs.dpt_pseudotime.to_numpy())\\\n    .assign(treatment=adata.obs.treatment)\\\n    .assign(treatment_codes=adata.obs.treatment.cat.codes.to_numpy())\\\n    .assign(DMSO=adata.obs.treatment == 'DMSO')\\\n    .assign(Ulixertinib=adata.obs.treatment == 'Ulixertinib')\ndf['ps_bins'] = pd.cut(df.pseudotime, bins=np.arange(0, 1.1, 0.05))\n\n\nfig, ax = plt.subplots(9,1,figsize=(9,2.5))\nfor idx, gene in enumerate(['pou5f1', 'nanog', 'fgf4', 'klf17']):\n    sns.heatmap(df[[gene]].T, cmap='Reds', cbar=False, xticklabels=False, ax=ax[idx])\nsns.heatmap(df[['DMSO']].T, cbar=False, cmap=['lightgrey', 'tab:blue'], xticklabels=False, ax=ax[4])\nsns.heatmap(df[['Ulixertinib']].T, cmap=['lightgrey', 'tab:orange'], cbar=False, xticklabels=False, ax=ax[5])\nsns.heatmap(df[['treatment_codes']].T, cbar=False, cmap=list(adata.uns['treatment_colors']), xticklabels=False, ax=ax[6])\nsns.heatmap(df[['predictions']].T, cbar=False, cmap=adata.obs.predictions.map(mouse_ct_colors).cat.categories.tolist(), xticklabels=False, ax=ax[7])\nsns.heatmap(df[['pseudotime']].T, cmap='viridis', cbar=False, xticklabels=False, ax=ax[8])\nfor ax_ in ax:\n    ax_.tick_params(axis='y', rotation=0)\nfig.suptitle('Trajectory from ICM to EPI')\nfig.savefig('../figures/12_niakan_mouse_pseudotime_ICM_EPI.pdf', bbox_inches='tight')\n\n\n\n\n\nax = (pd.crosstab(df.ps_bins, df.treatment, normalize='index') * 100).plot.bar(color=['tab:blue', 'lightgrey', 'tab:orange'], title='Treated cells over pseudotime', xlabel='Binned pseudotime', ylabel='% of cells')\nax.figure.savefig('../figures/12_niakan_mouse_pseudotime_ICM_EPI_treatment.pdf', bbox_inches='tight')"
  },
  {
    "objectID": "notebooks/04_mouse_integrationPlots.html#save-additional-stuff",
    "href": "notebooks/04_mouse_integrationPlots.html#save-additional-stuff",
    "title": "Niakan - Plots for cell type predictions",
    "section": "3 Save additional stuff",
    "text": "3 Save additional stuff\n\nadata = sc.read_h5ad('../results/12_niakan.mouse.withPredictions.h5ad')\n\ncounts = sc.read_h5ad(\"../data/assays/SCR_MP_20241207/processed/combined_matrix.h5ad\")\ncounts.var['gene_id'] = counts.var_names\ncounts.var_names = counts.var.gene_symbol.str.lower().values\ncounts.var_names_make_unique()\n\ncounts = counts[adata.obs_names, adata.var_names].copy()\ncounts.obs = adata.obs.copy()\ncounts.var = adata.var.copy()\n\ncounts.layers['counts'] = counts.X.copy()\n\nsc.pp.normalize_total(counts, target_sum=1_000_000)\ncounts.write('../results/12_niakan.mouse.PRM_withPredictions.h5ad')"
  },
  {
    "objectID": "notebooks/05_human_volcanoPlotsAndUmaps.html",
    "href": "notebooks/05_human_volcanoPlotsAndUmaps.html",
    "title": "simons_et_al",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport scanpy as sc\n\n\nsns.set_style(\"ticks\")\npalette_volcano = {\n    'NS': '#999999',\n    'UP': 'tab:orange',\n    'DOWN': 'tab:purple'\n}\n\n\nepiblast_degs = pd.read_table(\"/home/gkb340/Brickman/projects/proks-salehin-collaborations/results/11_niakan_EPI_DESeq2.csv\", delimiter=\",\")\n\n\nepiblast_degs['negLog10padj'] = -1 * np.log10(epiblast_degs['padj'])\nepiblast_degs['color'] = 'NS'\nepiblast_degs.loc[((epiblast_degs['padj'] &lt; 0.05) & (epiblast_degs['log2FoldChange'] &gt;= 1)),'color'] = 'UP'\nepiblast_degs.loc[((epiblast_degs['padj'] &lt; 0.05) & (epiblast_degs['log2FoldChange'] &lt;= -1)),'color'] = 'DOWN'\n\n\np = sns.scatterplot(data=epiblast_degs, x='log2FoldChange', y='negLog10padj', hue='color', palette=palette_volcano)\nplt.xlim(-30,30)\nplt.ylim(0,30)\nplt.xlabel('Log2(Fold Change) Ulix/DMSO')\nplt.ylabel('-Log10(Adjusted p-value)')\nplt.axvline(x=-1, color='black', linestyle='--')\nplt.axvline(x=1, color='black', linestyle='--')\nplt.axhline(y=np.log10(1/0.05), color='black', linestyle='--')\nsns.despine(offset=2, trim=True)\n\n\n\n\n\npre_degs = pd.read_table(\"/home/gkb340/Brickman/projects/proks-salehin-collaborations/results/11_niakan_PrE_DESeq2.csv\", delimiter=\",\")\n\n\npre_degs['negLog10padj'] = -1 * np.log10(pre_degs['padj'])\npre_degs['color'] = 'NS'\npre_degs.loc[((pre_degs['padj'] &lt; 0.05) & (pre_degs['log2FoldChange'] &gt;= 1)),'color'] = 'UP'\npre_degs.loc[((pre_degs['padj'] &lt; 0.05) & (pre_degs['log2FoldChange'] &lt;= -1)),'color'] = 'DOWN'\n\n\np = sns.scatterplot(data=pre_degs, x='log2FoldChange', y='negLog10padj', hue='color', palette=palette_volcano)\nplt.xlim(-30,30)\nplt.ylim(0,40)\nplt.xlabel('Log2(Fold Change) Ulix/DMSO')\nplt.ylabel('-Log10(Adjusted p-value)')\nplt.axvline(x=-1, color='black', linestyle='--')\nplt.axvline(x=1, color='black', linestyle='--')\nplt.axhline(y=np.log10(1/0.05), color='black', linestyle='--')\nsns.despine(offset=2, trim=True)\n\n\n\n\n\nte_degs = pd.read_table(\"/home/gkb340/Brickman/projects/proks-salehin-collaborations/results/11_niakan_TE_DESeq2.csv\", delimiter=\",\")\n\n\nte_degs['negLog10padj'] = -1 * np.log10(te_degs['padj'])\nte_degs['color'] = 'NS'\nte_degs.loc[((te_degs['padj'] &lt; 0.05) & (te_degs['log2FoldChange'] &gt;= 1)),'color'] = 'UP'\nte_degs.loc[((te_degs['padj'] &lt; 0.05) & (te_degs['log2FoldChange'] &lt;= -1)),'color'] = 'DOWN'\n\n\np = sns.scatterplot(data=te_degs, x='log2FoldChange', y='negLog10padj', hue='color', palette=palette_volcano)\nplt.xlim(-35,35)\nplt.ylim(0,45)\nplt.xlabel('Log2(Fold Change) Ulix/DMSO')\nplt.ylabel('-Log10(Adjusted p-value)')\nplt.axvline(x=-1, color='black', linestyle='--')\nplt.axvline(x=1, color='black', linestyle='--')\nplt.axhline(y=np.log10(1/0.05), color='black', linestyle='--')\nsns.despine(offset=2, trim=True)\n\n\n\n\n\nniakan_adata = sc.read_h5ad(\"../results/niakan_08.withPredictions.adata.h5ad\")\n\n\nENSG_to_SYMBOL = pd.read_table(\"../results/GRCh38.110.ENSG_to_SYMBOL.csv\", delimiter=',')\nENSG_to_SYMBOL = ENSG_to_SYMBOL.set_index('ensembl')\n\n\nniakan_adata.raw.var['gene_symbol'] = ENSG_to_SYMBOL.loc[niakan_adata.raw.var.index.values,'symbol']\n\n\nniakan_adata.var['gene_symbol'] = ENSG_to_SYMBOL.loc[niakan_adata.var.index.values,'symbol']\n\n\nsc.pl.umap(niakan_adata, color=\"prediction\", ncols=2)\n\n\n\n\n\nENSG_to_SYMBOL = pd.read_table(\"../results/GRCh38.110.ENSG_to_SYMBOL.csv\", delimiter=',')\nENSG_to_SYMBOL = ENSG_to_SYMBOL.set_index('symbol')\n\n\n# NANOG: ENSG00000111704 \n# SOX2: ENSG00000181449 \n# GATA4: ENSG00000136574\n# SOX17: ENSG00000164736\n\n\nsc.pl.umap(niakan_adata, color=ENSG_to_SYMBOL.loc[['NANOG','SOX2','GATA4','SOX17'],'ensembl'], ncols=2, cmap='plasma')\n\n\n\n\n\nsc.pl.umap(niakan_adata, color=ENSG_to_SYMBOL.loc[['KLF17','TDGF1','PDGFRA','GATA6','GATA2','GATA3','KRT18','TEAD3'],'ensembl'], ncols=2, cmap='plasma')\n\n\n\n\n\ndef split_umap(adata, split_by, ncol=2, nrow=None, **kwargs):\n    categories = adata.obs[split_by].cat.categories\n    if nrow is None:\n        nrow = int(np.ceil(len(categories) / ncol))\n    fig, axs = plt.subplots(nrow, ncol, figsize=(4*ncol, 3*nrow))\n    axs = axs.flatten()\n    for i, cat in enumerate(categories):\n        ax = axs[i]\n        sc.pl.umap(adata[adata.obs[split_by] == cat], ax=ax, show=False, title=cat, size=500, cmap='plasma', **kwargs)\n    return plt.tight_layout()\n\n\nsplit_umap(niakan_adata, split_by='treatment', color=ENSG_to_SYMBOL.loc[['NANOG'],'ensembl'])\n\n\n\n\n\nsplit_umap(niakan_adata, split_by='treatment', color=ENSG_to_SYMBOL.loc[['POU5F1'],'ensembl'])\n\n\n\n\n\nsplit_umap(niakan_adata, split_by='treatment', color=ENSG_to_SYMBOL.loc[['SOX2'],'ensembl'])\n\n\n\n\n\nsplit_umap(niakan_adata, split_by='treatment', color=ENSG_to_SYMBOL.loc[['GATA4'],'ensembl'])\n\n\n\n\n\nsplit_umap(niakan_adata, split_by='treatment', color=ENSG_to_SYMBOL.loc[['SOX17'],'ensembl'])\n\n\n\n\n\nsplit_umap(niakan_adata, split_by='treatment', color=ENSG_to_SYMBOL.loc[['KLF17'],'ensembl'])\n\n\n\n\n\nsplit_umap(niakan_adata, split_by='treatment', color=ENSG_to_SYMBOL.loc[['TDGF1'],'ensembl'])\n\n\n\n\n\nsplit_umap(niakan_adata, split_by='treatment', color=ENSG_to_SYMBOL.loc[['PDGFRA'],'ensembl'])\n\n\n\n\n\nsplit_umap(niakan_adata, split_by='treatment', color=ENSG_to_SYMBOL.loc[['GATA6'],'ensembl'])\n\n\n\n\n\nsplit_umap(niakan_adata, split_by='treatment', color=ENSG_to_SYMBOL.loc[['GATA2'],'ensembl'])\n\n\n\n\n\nsplit_umap(niakan_adata, split_by='treatment', color=ENSG_to_SYMBOL.loc[['GATA3'],'ensembl'])\n\n\n\n\n\nsplit_umap(niakan_adata, split_by='treatment', color=ENSG_to_SYMBOL.loc[['KRT18'],'ensembl'])\n\n\n\n\n\nsplit_umap(niakan_adata, split_by='treatment', color=ENSG_to_SYMBOL.loc[['TEAD3'],'ensembl'])\n\n\n\n\n\ncoarse_predictions = {\n    'Epiblast_6.0': 'Epiblast and ICM',\n    'Epiblast_7.0': 'Epiblast and ICM',\n    'Late epiblast': 'Epiblast and ICM',\n    'Inner Cell Mass': 'Epiblast and ICM',\n    'Primitive Endoderm': 'Primitive Endoderm',\n    'Trophectoderm_6.0': 'Trophectoderm',\n    'Trophectoderm_7.0': 'Trophectoderm',\n    'Trophectoderm_8.0': 'Trophectoderm',\n    'Trophectoderm_9.0': 'Trophectoderm',\n \n}\n\n\nniakan_adata.obs['coarse_predictions'] = niakan_adata.obs.prediction.map(coarse_predictions)\n\n\nsc.pl.stacked_violin(niakan_adata[niakan_adata.obs.treatment == 'DMSO'], ['NANOG','SOX2','KLF17','TDGF1','GATA4','SOX17','PDGFRA','GATA6','GATA2','GATA3','KRT18','TEAD3'], dendrogram=False, gene_symbols='gene_symbol', groupby='coarse_predictions')\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/anndata/_core/anndata.py:1209: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n  df[key] = c\n\n\n\n\n\n\nsc.pl.stacked_violin(niakan_adata[niakan_adata.obs.treatment == 'Ulix'], ['NANOG','SOX2','KLF17','TDGF1','GATA4','SOX17','PDGFRA','GATA6','GATA2','GATA3','KRT18','TEAD3'], dendrogram=False, gene_symbols='gene_symbol', groupby='coarse_predictions')\n\n/projects/dan1/data/Brickman/conda/envs/scvi-1.1.5/lib/python3.10/site-packages/anndata/_core/anndata.py:1209: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n  df[key] = c"
  }
]